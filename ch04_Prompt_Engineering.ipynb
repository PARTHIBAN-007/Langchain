{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework for developing applications powered by large language models (LLMs).\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "\n",
    "llm = GoogleGenerativeAI(\n",
    "    model = \"gemini-1.5-flash\",\n",
    "    temperature= 0.7 ,\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"What is Langchain in one line\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The answer is 8.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_shot_prompt = \"\"\"\n",
    "Example:\n",
    "Q: What is 2 + 2?\n",
    "A: The answer is 4.\n",
    "\n",
    "Now answer this:\n",
    "Q: What is 5 + 3?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(one_shot_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 16.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Examples:\n",
    "Q: What is 2 + 2?\n",
    "A: The answer is 4.\n",
    "\n",
    "Q: What is 5 + 3?\n",
    "A: The answer is 8.\n",
    "\n",
    "Now answer this:\n",
    "Q: What is 10 + 6?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(few_shot_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Step 1: Identify the knowns.**\n",
      "\n",
      "* Speed (v) = 60 km/hr\n",
      "* Time (t) = 2 hours\n",
      "\n",
      "**Step 2: Identify the unknown.**\n",
      "\n",
      "* Distance (d) = ?\n",
      "\n",
      "**Step 3: Choose the appropriate formula.**\n",
      "\n",
      "The formula relating speed, time, and distance is:\n",
      "\n",
      "Distance = Speed × Time   or  d = v × t\n",
      "\n",
      "**Step 4: Substitute the known values into the formula.**\n",
      "\n",
      "d = 60 km/hr × 2 hr\n",
      "\n",
      "**Step 5: Calculate the distance.**\n",
      "\n",
      "d = 120 km\n",
      "\n",
      "**Answer:** The train travels 120 kilometers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cot_prompt = \"\"\"\n",
    "Solve this problem step by step\n",
    "Q: If a train moves at 60 km/hr for 2 hours, how far does it travel?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(cot_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to access real-time information to answer this question accurately.  My knowledge is not connected to a live news feed.  Therefore I cannot provide the latest news about AI.\n",
      "Answer: I do not have access to real-time information, so I cannot provide the latest news about AI.  To find the latest news, I recommend searching a reputable news source online.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "react_prompt = \"\"\"\n",
    "You are an AI agent that answers questions by reasoning and taking actions.\n",
    "\n",
    "Q: What is the capital of France?\n",
    "Thought: I know this from memory.\n",
    "Answer: The capital of France is Paris.\n",
    "\n",
    "Q: What is the latest news about AI?\n",
    "Thought: I need to look this up online.\n",
    "Action: Search for \"latest AI news\".\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(react_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're teaching a dog a trick.  You show it what to do, reward it when it gets it right, and correct it when it's wrong.  Over time, the dog learns.\n",
      "\n",
      "Artificial intelligence (AI) is similar.  It's about teaching computers to learn and solve problems like humans do, but without explicitly programming every single step.  We feed computers lots of data (like showing the dog the trick repeatedly), and they use algorithms (like the dog's brain) to find patterns and make decisions.\n",
      "\n",
      "So, AI can do things like:\n",
      "\n",
      "* **Recognize faces in photos:**  Like a dog recognizing its owner.\n",
      "* **Translate languages:**  Like a parrot mimicking sounds, but understanding the meaning.\n",
      "* **Recommend movies you might like:**  Like a friend suggesting something based on your tastes.\n",
      "* **Drive a car:**  Like a skilled driver navigating roads.\n",
      "\n",
      "It's not about creating conscious robots, but about building systems that can learn, adapt, and perform tasks intelligently.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in simple terms.\"\n",
    ")\n",
    "\n",
    "formatted_prompt = template.format(topic=\"Artificial Intelligence\")\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imagine you have a really smart robot.  It\\'s not just following instructions like a simple computer program; it\\'s actually *taking action* in the world to achieve goals.  That\\'s what \"agentic AI\" is all about.\\n\\nAgentic AI refers to artificial intelligence systems that are *agents*.  An agent is something that can:\\n\\n1. **Perceive:** It can \"see\" or \"sense\" its environment (like a robot seeing with cameras, or a software agent reading data from a website).\\n\\n2. **Reason:** It can think about what it\\'s sensing and decide what to do.  It might need to plan or strategize.\\n\\n3. **Act:** It can take actions in the world to achieve its goals. This could be moving a robot arm, sending an email, or changing something in a computer game.\\n\\nSo, instead of just passively processing information, an agentic AI *actively* interacts with its environment to accomplish something.  Think of a self-driving car – it perceives the road, reasons about traffic, and acts by steering, braking, and accelerating. That\\'s an example of agentic AI in action!  It\\'s not just reacting; it\\'s proactively working towards its goal of getting you to your destination safely.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"What is called Agentic AI\"\n",
    "context = \"Provide Explanation easy for beginner\"\n",
    "\n",
    "meta_prompt_template = \"\"\"\n",
    "You are an AI tutor designed to explain concepts in a beginnerr friendly\n",
    "User question: {user_query}\n",
    "Context: {context}\n",
    "Now generate a response:\n",
    "\"\"\"\n",
    "\n",
    "meta_prompt = meta_prompt_template.format(user_query=user_query,context=context)\n",
    "response = llm.invoke(meta_prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your explanation of deep learning is already quite comprehensive and well-written. Here are some suggestions for improvement, focusing on clarity, conciseness, and adding a few details:\n",
      "\n",
      "**1.  Streamline the Introduction:**\n",
      "\n",
      "Instead of:  \"Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers (hence \"deep\") to analyze data and solve complex problems. Instead of relying on explicitly programmed rules, deep learning algorithms learn from vast amounts of data through a process called training.\"\n",
      "\n",
      "Try: \"Deep learning is a powerful subfield of machine learning that uses artificial neural networks with multiple layers to learn complex patterns from data. Unlike traditional methods relying on explicitly programmed rules, deep learning learns directly from vast datasets.\"\n",
      "\n",
      "This version is more concise and directly highlights the key differentiator: learning from data instead of explicit rules.\n",
      "\n",
      "\n",
      "**2. Clarify the Role of Weights and Biases:**\n",
      "\n",
      "In the \"Learning through Training\" section, you mention adjusting weights and biases.  You could add a sentence explaining what they *do*.  For example:  \"This error is then used to adjust the *weights and biases of the connections between neurons, which determine the strength and influence of each connection*, iteratively improving the network's accuracy.\"\n",
      "\n",
      "**3.  Expand on Optimization:**\n",
      "\n",
      "Briefly mentioning different optimization algorithms beyond gradient descent would be beneficial.  You could add:  \"Algorithms like gradient descent, Adam, and RMSprop are used to find the optimal weights and biases that minimize the error.\"\n",
      "\n",
      "**4.  Elaborate on Feature Extraction:**\n",
      "\n",
      "Your explanation of feature extraction is good, but you could add a sentence emphasizing the hierarchical nature of feature learning: \"This hierarchical learning allows the network to build upon simpler features to learn increasingly complex and abstract representations of the data.\"\n",
      "\n",
      "**5.  Add a Note on Data Preprocessing:**\n",
      "\n",
      "Deep learning models are highly sensitive to the quality of data.  Adding a brief mention of data preprocessing (cleaning, normalization, etc.) would be helpful.  You could include a sentence like: \"Effective deep learning requires careful preprocessing of the data to ensure its quality and suitability for the model.\"\n",
      "\n",
      "**6.  Simplify the \"In simpler terms\" analogy:**\n",
      "\n",
      "While the cat analogy is good, it could be even simpler: \"Imagine showing a computer thousands of pictures of cats and dogs. Deep learning allows the computer to learn the visual differences between them without being explicitly told what defines a cat or a dog.\"\n",
      "\n",
      "**7.  Consider Adding a Section on Challenges:**\n",
      "\n",
      "Adding a section briefly discussing challenges in deep learning, such as:\n",
      "\n",
      "* **Computational cost:** Training deep learning models can be computationally expensive.\n",
      "* **Data requirements:**  Large, high-quality datasets are crucial.\n",
      "* **Interpretability (the \"black box\" problem):** Understanding *why* a deep learning model makes a specific prediction can be difficult.\n",
      "* **Overfitting:**  The model might perform well on training data but poorly on unseen data.\n",
      "\n",
      "\n",
      "**8.  Refine the Conclusion:**\n",
      "\n",
      "Instead of: \"Deep learning's power comes from its ability to learn complex patterns from data without explicit programming, leading to breakthroughs in various fields. However, it requires significant computational resources and large datasets for effective training.\"\n",
      "\n",
      "Try: \"Deep learning's ability to learn complex patterns directly from data has revolutionized many fields.  While powerful, it requires substantial computational resources and large, high-quality datasets, and its inherent complexity presents challenges in terms of interpretability and avoiding overfitting.\"\n",
      "\n",
      "\n",
      "By incorporating these suggestions, you can make your explanation even clearer, more precise, and more comprehensive. Remember to maintain a balance between detail and accessibility; the goal is to inform a broad audience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_response = llm.invoke(\"Explain deep learning.\")\n",
    "\n",
    "refinement_prompt = f\"\"\"\n",
    "Here is my initial response:\n",
    "{initial_response}\n",
    "\n",
    "How can I improve this explanation? Suggest better wording or add missing details.\n",
    "\"\"\"\n",
    "\n",
    "improved_response = llm.invoke(refinement_prompt)\n",
    "print(improved_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
