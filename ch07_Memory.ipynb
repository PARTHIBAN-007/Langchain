{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework for developing applications powered by large language models (LLMs).\n",
      "\n",
      "LangChain handles memory through various memory types, allowing chains of interactions with LLMs to retain and utilize information from previous interactions within a conversation or across multiple calls.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "\n",
    "llm = GoogleGenerativeAI(model = \"gemini-1.5-flash\")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"question\"], \n",
    "                        template=\"History: {history}\\nUser: {question}\\nAI:\")\n",
    "\n",
    "chain = LLMChain(llm= llm, memory = memory , prompt = prompt)\n",
    "\n",
    "response1 = chain.run(question=\"What is LangChain?.Explain it in single line\")\n",
    "print(response1)\n",
    "\n",
    "response2 = chain.run(question = \"How does it handle memory ?\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are AI models that process sequential data using self-attention mechanisms to weigh the importance of different parts of the input.\n",
      "\n",
      "The key difference between Transformers and Recurrent Neural Networks (RNNs) lies in how they process sequential data:\n",
      "\n",
      "* **RNNs process sequences sequentially:** RNNs process input data one step at a time, maintaining a hidden state that captures information from previous steps.  This sequential processing makes them inherently slow for long sequences, as they need to process each element before moving to the next.  They also suffer from the vanishing/exploding gradient problem, making it difficult to learn long-range dependencies.\n",
      "\n",
      "* **Transformers process sequences in parallel:** Transformers use self-attention mechanisms to weigh the importance of different parts of the input *simultaneously*.  This allows them to capture long-range dependencies much more effectively than RNNs and enables significant speed improvements through parallelization on hardware like GPUs.  They don't need to process the sequence step-by-step.\n",
      "\n",
      "Here's a table summarizing the key differences:\n",
      "\n",
      "| Feature          | RNN                               | Transformer                           |\n",
      "|-----------------|------------------------------------|---------------------------------------|\n",
      "| Processing       | Sequential                          | Parallel                              |\n",
      "| Long-range dependencies | Difficult to learn                 | Easier to learn                      |\n",
      "| Speed            | Slow, especially for long sequences | Fast, even for long sequences        |\n",
      "| Parallelism      | Limited                            | High                                  |\n",
      "| Vanishing/Exploding Gradients | Prone to this problem             | Less prone to this problem           |\n",
      "| Memory Efficiency | Can be memory-efficient for short sequences | Can be less memory-efficient for very long sequences (depending on implementation) |\n",
      "\n",
      "\n",
      "In essence, Transformers offer a more efficient and powerful approach to processing sequential data, particularly for long sequences, compared to RNNs. While RNNs still have their uses in specific scenarios, Transformers have largely superseded them in many natural language processing tasks and are increasingly applied to other sequential data domains.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(llm = llm)\n",
    "\n",
    "chain = LLMChain(llm= llm, memory = memory , prompt = prompt)\n",
    "\n",
    "response1 = chain.run(question=\"What is Transformers in AI?.Explain it in single line\")\n",
    "print(response1)\n",
    "\n",
    "response2 = chain.run(question = \"How it diifers from RNN?\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relationship between AI, machine learning, and deep learning is hierarchical:\n",
      "\n",
      "* **AI (Artificial Intelligence)** is the broadest concept, encompassing any technique that enables computers to mimic human intelligence.  This includes a wide range of approaches, not just machine learning.\n",
      "\n",
      "* **Machine Learning (ML)** is a *subset* of AI. It focuses on specific AI techniques that allow computers to learn from data without explicit programming.  Instead of relying on hard-coded rules, ML algorithms identify patterns in data and use these patterns to make predictions or decisions.\n",
      "\n",
      "* **Deep Learning (DL)** is a *subset* of machine learning.  It uses artificial neural networks with multiple layers to learn complex patterns from data.  Deep learning can be considered a more advanced and powerful form of machine learning, particularly effective for unstructured data like images and text, where traditional machine learning techniques might struggle.\n",
      "\n",
      "Think of it like Russian nesting dolls: AI is the largest doll, containing machine learning, which in turn contains deep learning.  All deep learning is machine learning, and all machine learning is AI, but not all AI is machine learning, and not all machine learning is deep learning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=3)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "response1 = chain.run(question=\"What is AI?\")\n",
    "response2 = chain.run(question=\"What is machine learning?\")\n",
    "response3 = chain.run(question=\"What is deep learning?\")\n",
    "response4 = chain.run(question=\"How do they relate?\")  \n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationEntityMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Alex.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationEntityMemory\n",
    "\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "response1 = chain.run(question=\"My name is Alex. Remember that.\")\n",
    "response2 = chain.run(question=\"Whatâ€™s my name?\")\n",
    "print(response2)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
