{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key = gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain is a framework for developing applications powered by large language models (LLMs).  It simplifies the process of building LLM-based applications by providing tools and components for:\\n\\n* **Connecting to various LLMs:**  It allows you to easily switch between different LLMs (like OpenAI's GPT models, Hugging Face models, etc.) without modifying your core application code.\\n\\n* **Managing interactions with LLMs:** It handles prompt engineering, chaining multiple calls to LLMs, and managing the context of the conversation.\\n\\n* **Integrating with other data sources:**  It allows you to connect LLMs to your own databases, documents, APIs, and other data sources to provide them with more context and capabilities.\\n\\n* **Building different application types:** LangChain provides building blocks for various applications such as chatbots, question-answering systems, summarization tools, and more.\\n\\nIn essence, LangChain acts as an abstraction layer, making it easier to work with LLMs and build more complex and powerful applications.  Instead of writing all the boilerplate code yourself for managing LLMs and external data, LangChain provides pre-built components to accelerate development.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = GoogleGenerativeAI(model = \"gemini-1.5-flash\",temperature=0.7)\n",
    "\n",
    "response = llm.invoke(\"What is called langchain\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parthiban\\AppData\\Local\\Temp\\ipykernel_13696\\3364858757.py:5: LangChainDeprecationWarning: This class is deprecated and will be removed in langchain 1.0. See API reference for replacement: https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_math.base.LLMMathChain.html\n",
      "  llm_math = LLMMathChain(llm=llm)\n",
      "d:\\Users\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:175: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "llm_math = LLMMathChain(llm=llm)\n",
    "\n",
    "math_tool = Tool(\n",
    "    name= \"calculator\",\n",
    "    func = llm_math.run ,\n",
    "    description= \"Useful for when you need to answer questions about math.\"\n",
    ")\n",
    "\n",
    "tools = [math_tool]\n",
    "\n",
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm = llm\n",
    ")\n",
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parthiban\\AppData\\Local\\Temp\\ipykernel_13696\\298812146.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  zero_shot_agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parthiban\\AppData\\Local\\Temp\\ipykernel_13696\\2247149980.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  zero_shot_agent(\"what is (4.5*2.1)^2.2?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate (4.5 * 2.1) raised to the power of 2.2.  I can use the calculator for this.\n",
      "Action: Calculator\n",
      "Action Input: (4.5 * 2.1)**2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: 139.94261298333066\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.94261298333066"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4.5*2.1)**2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate the total number of apples.  First, I need to find the total number of apples in the apple boxes, and then add that to the number of apples Mary has.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: 2.5 * 8\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 20.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Now I need to add Mary's apples to the total from the apple boxes.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: 20 + 4\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 24\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: 24\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'if Mary has four apples and Giorgio brings two and a half apple boxes (apple box contains eight apples), how many apples do we have?',\n",
       " 'output': '24'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I don't need a calculator to answer this question.  I need to access general knowledge.\n",
      "Thought: I know the capital of Norway is Oslo.\n",
      "Final Answer: Oslo\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the capital of Norway?', 'output': 'Oslo'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is the capital of Norway?\") # No need for tool"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
