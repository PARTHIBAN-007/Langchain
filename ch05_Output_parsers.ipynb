{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import google.generativeai as genai\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_api_key\n",
    "genai.configure(api_key=gemini_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response :  LangChain is a framework for developing applications powered by large language models (LLMs).  It's designed to make it easier to build more complex and useful LLM-based applications beyond simple prompt-and-response interactions.  Instead of just sending a prompt to an LLM and getting a response, LangChain provides tools and abstractions to:\n",
      "\n",
      "* **Connect LLMs to other sources of data:**  This is a key feature.  LangChain allows you to connect LLMs to your own documents, databases, APIs, and other knowledge sources.  This lets the LLM access and process information beyond its pre-trained knowledge, making it much more powerful and adaptable.  This is often referred to as augmenting the LLM with external knowledge.\n",
      "\n",
      "* **Chain multiple LLMs together:**  You can create sequences of calls to different LLMs, each performing a specific task in a larger workflow.  For example, one LLM might summarize a document, and another might answer questions based on that summary.\n",
      "\n",
      "* **Manage memory:** LangChain offers mechanisms to give LLMs memory of past interactions within a conversation, improving context and coherence.  This is crucial for building more sophisticated conversational agents.\n",
      "\n",
      "* **Implement agents:**  These are programs that decide which LLMs or tools to use based on a given task.  Agents can significantly improve the ability of your application to handle complex requests autonomously.\n",
      "\n",
      "* **Support various LLMs:** LangChain supports a wide range of LLMs, including OpenAI, Hugging Face Hub models, and others, making it flexible and adaptable to different needs and budgets.\n",
      "\n",
      "**Key Components of LangChain:**\n",
      "\n",
      "* **Models:**  The core LLMs that provide the language understanding and generation capabilities.\n",
      "* **Prompts:**  The interfaces used to interact with the models. LangChain helps you design and manage prompts effectively.\n",
      "* **Indexes:**  Methods to structure and access external data sources for the LLM.\n",
      "* **Chains:**  Sequences of calls to models and other components, orchestrating complex workflows.\n",
      "* **Agents:**  Autonomous systems that decide how to use chains and tools to achieve a goal.\n",
      "* **Callbacks:**  Mechanisms to track and monitor the execution of LangChain applications.\n",
      "\n",
      "\n",
      "**What LangChain is *not*:**\n",
      "\n",
      "LangChain is not an LLM itself. It's a framework that *uses* LLMs as building blocks to create more advanced applications.  It doesn't train LLMs; it leverages pre-trained models.\n",
      "\n",
      "**In short:** LangChain simplifies the process of building powerful and versatile applications that leverage the capabilities of LLMs by providing tools for data connection, workflow management, memory, and agent-based interaction.  It's a powerful tool for anyone looking to go beyond simple LLM integrations and build more sophisticated AI-powered systems.\n",
      "\n",
      "Parsed Output :  LangChain is a framework for developing applications powered by large language models (LLMs).  It's designed to make it easier to build more complex and useful LLM-based applications beyond simple prompt-and-response interactions.  Instead of just sending a prompt to an LLM and getting a response, LangChain provides tools and abstractions to:\n",
      "\n",
      "* **Connect LLMs to other sources of data:**  This is a key feature.  LangChain allows you to connect LLMs to your own documents, databases, APIs, and other knowledge sources.  This lets the LLM access and process information beyond its pre-trained knowledge, making it much more powerful and adaptable.  This is often referred to as augmenting the LLM with external knowledge.\n",
      "\n",
      "* **Chain multiple LLMs together:**  You can create sequences of calls to different LLMs, each performing a specific task in a larger workflow.  For example, one LLM might summarize a document, and another might answer questions based on that summary.\n",
      "\n",
      "* **Manage memory:** LangChain offers mechanisms to give LLMs memory of past interactions within a conversation, improving context and coherence.  This is crucial for building more sophisticated conversational agents.\n",
      "\n",
      "* **Implement agents:**  These are programs that decide which LLMs or tools to use based on a given task.  Agents can significantly improve the ability of your application to handle complex requests autonomously.\n",
      "\n",
      "* **Support various LLMs:** LangChain supports a wide range of LLMs, including OpenAI, Hugging Face Hub models, and others, making it flexible and adaptable to different needs and budgets.\n",
      "\n",
      "**Key Components of LangChain:**\n",
      "\n",
      "* **Models:**  The core LLMs that provide the language understanding and generation capabilities.\n",
      "* **Prompts:**  The interfaces used to interact with the models. LangChain helps you design and manage prompts effectively.\n",
      "* **Indexes:**  Methods to structure and access external data sources for the LLM.\n",
      "* **Chains:**  Sequences of calls to models and other components, orchestrating complex workflows.\n",
      "* **Agents:**  Autonomous systems that decide how to use chains and tools to achieve a goal.\n",
      "* **Callbacks:**  Mechanisms to track and monitor the execution of LangChain applications.\n",
      "\n",
      "\n",
      "**What LangChain is *not*:**\n",
      "\n",
      "LangChain is not an LLM itself. It's a framework that *uses* LLMs as building blocks to create more advanced applications.  It doesn't train LLMs; it leverages pre-trained models.\n",
      "\n",
      "**In short:** LangChain simplifies the process of building powerful and versatile applications that leverage the capabilities of LLMs by providing tools for data connection, workflow management, memory, and agent-based interaction.  It's a powerful tool for anyone looking to go beyond simple LLM integrations and build more sophisticated AI-powered systems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "llm = GoogleGenerativeAI(\n",
    "    model = \"gemini-1.5-flash\",\n",
    "    temperature= 0.7 ,\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "response = llm.invoke(\"Tell me about Langchain\")\n",
    "print(\"LLM Response : \",response)\n",
    "parsed_output = parser.parse(response)\n",
    "print(\"Parsed Output : \",parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCQGenerator(question='Which of the following is NOT a common application of Large Language Models (LLMs)?', answer='d', options=['a) Text generation', 'b) Machine translation', 'c) Chatbots and conversational AI', 'd) Predicting stock market prices with 100% accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class MCQGenerator(BaseModel):\n",
    "    question : str\n",
    "    answer : str\n",
    "    options : list[str]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=MCQGenerator)\n",
    "\n",
    "prompt = \"\"\"\n",
    "Provide a structured JSON output with the following fields:\n",
    "- question\n",
    "- answer\n",
    "- options (a list of possible answers)\n",
    "Create an MCQ based on Large Language Models.\n",
    "\n",
    "Format it strictly as JSON.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "parsed_output = parser.parse(response)\n",
    "parsed_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
